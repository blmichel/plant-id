# local setup: path to data and mapping file
BASE_DATA_DIRNAME: '/Users/blmichel/Documents/docs/ml/data/inat2021/'
MAPPING_FILE_DIRNAME: '/Users/blmichel/Documents/docs/ml/repos/plant-id-refactor/dev/plant_id/metadata/'

# training options
NUM_EPOCHS: 3
BATCH_SIZE: 48
LIMIT_TRAIN_BATCHES: 1.0
RESOLUTION: 260
TRAIN_SET: 'mini'

# logging and GPU options
USE_WANDB: False
WANDB_PROJECT_NAME: 'test-1'
DEVICES: -1
ACCELERATOR: 'gpu'

# model options
PRETRAINED_STEM: 'tf_efficientnetv2_s_in21k'
LOADED_MODEL: None # None or 'path_to_litmodel.pkl'
HEAD_DWSCONV: True
FC_DIM: 4271 # default: 4271 (number of plant classes in iNat2021)
FC_DROPOUT: 0

# optimizer options
OPTIMIZER: "AdamW"
LR: 5e-4 # default 1e-3
WEIGHT_DECAY: 0.01 # default 0.01
PRECISION: 16 # 16 for AMP, 32 for standard training (on MPS this is disabled)
LOSS: "cross_entropy" # "cross_entropy" or "arcface"
LAYERWISE_LR_DECAY: False
LLRD_COEFF: 0.8

# scheduler options
EARLY_STOPPING: True
REDUCE_LR_ON_PLATEAU: False
ROP_COEFF: 0.75
ROP_THRESHOLD: 0.01
ROP_THRESHOLD_MODE: 'abs'
ONE_CYCLE_LR: False
ONE_CYCLE_MAX_LR: 5e-4
ONE_CYCLE_TOTAL_STEPS: 100 # not used except for 1cycle LR scheduler
STOCHASTIC_WEIGHT_AVERAGING: False

# tuner options
AUTO_LR_FIND: False # True or False
AUTO_SCALE_BATCH_SIZE: None # 'power', 'binsearch' or None